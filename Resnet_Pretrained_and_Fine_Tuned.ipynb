{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wyMfEAy9lGG"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import seaborn as sns\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "s9ANQdgD-9mi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa6fd8e-5d4c-4940-c5e1-5d9ffd1a7eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"torch version:\", torch.__version__)\n",
        "print(\"device:\", device)"
      ],
      "metadata": {
        "id": "uMAzqZP9rC3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af14a740-005c-4371-ff7c-3303db5d823c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.1.0+cu121\n",
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "destination_directory = '/content/gdrive/MyDrive/Physionet_NPY_DATA/'"
      ],
      "metadata": {
        "id": "vq1X3VjZ-_BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_file_path = destination_directory + 'X_train.npy'\n",
        "X_test_file_path = destination_directory + 'X_test.npy'\n",
        "y_train_file_path = destination_directory + 'y_train.npy'\n",
        "y_test_file_path = destination_directory + 'y_test.npy'"
      ],
      "metadata": {
        "id": "tkynlgAr_Es-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_file_path"
      ],
      "metadata": {
        "id": "dL1MD3TSJB1x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "29e15cc4-2074-4a99-e8f3-763e3a3dbc67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Physionet_NPY_DATA/X_train.npy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.load(X_train_file_path, allow_pickle=True)\n",
        "X_test = np.load(X_test_file_path, allow_pickle=True)\n",
        "y_train = np.load(y_train_file_path, allow_pickle=True)\n",
        "y_test = np.load(y_test_file_path, allow_pickle=True)"
      ],
      "metadata": {
        "id": "sKSizCny_Fu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.reshape(len(y_train), 1)\n",
        "y_test = y_test.reshape(len(y_test), 1)"
      ],
      "metadata": {
        "id": "eX11je7sNLOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[:10000,:,:]"
      ],
      "metadata": {
        "id": "cbPfh8RSYWHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaUcYYjmgLJQ",
        "outputId": "956ef94a-5d5c-4e88-8be4-14c240fbba49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 5000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train[:10000]"
      ],
      "metadata": {
        "id": "4XCDTPG9gNX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_list = y_train.tolist()\n",
        "\n",
        "temp = None\n",
        "faulty_set = list()\n",
        "count = 0\n",
        "for items in y_train:\n",
        "\n",
        "    if len(items[0]) == 0:\n",
        "       count += 1\n",
        "       temp = items\n",
        "       faulty_set.append(temp)\n",
        "       continue\n",
        "\n",
        "X_train = X_train[np.where(y_train != temp)[0]]\n",
        "y_train = y_train[np.where(y_train != temp)[0]]\n",
        "X_test = X_test[np.where(y_test != temp)[0]]\n",
        "y_test = y_test[np.where(y_test != temp)[0]]"
      ],
      "metadata": {
        "id": "C65ofspRK-SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QBDi8IPyC6H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "SrnKFSsDGWic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d555767-7fd7-4f37-df4a-876dfcf30ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9854, 5000, 12), (1901, 5000, 12), (9854, 1), (1901, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xY2xVWCOP0zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of one ECG\n",
        "np.array(X_train[0]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S35KHHrB5c9o",
        "outputId": "0b2cbee4-935a-4628-d72e-29a9db955a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "unique_values = np.unique(np.concatenate(y_train.flatten()))\n",
        "print(f'All Labels: {unique_values}')"
      ],
      "metadata": {
        "id": "F-nyqRyO6zO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f94053a-c72c-4bc0-cff4-635699d182a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Labels: ['CD' 'HYP' 'MI' 'NORM' 'STTC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_out = list()\n",
        "y_out = list()\n",
        "to_pop = list()\n",
        "sample_size = 1\n",
        "count = 0\n",
        "for i in y_train:\n",
        "    if i[0] == ['CD']:\n",
        "        x_out.append(X_train[count])\n",
        "        y_out.append(y_train[count])\n",
        "        to_pop.append(count)\n",
        "        X_train = np.delete(X_train, count, axis=0)\n",
        "        y_train = np.delete(y_train, count, axis=0)\n",
        "        break\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "2q3e0gcH9psC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(x_out).shape, np.array(y_out).shape"
      ],
      "metadata": {
        "id": "DNdiI4c_BZgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50821387-40bc-4835-9890-5358711c070a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1, 5000, 12), (1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmhdz9gTQeSe",
        "outputId": "7f4c655d-4da9-4552-cd30-6cc1a244b4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.009,  0.144,  0.153, ..., -0.051, -0.099, -0.066],\n",
              "        [-0.012,  0.192,  0.204, ..., -0.068, -0.132, -0.088],\n",
              "        [-0.015,  0.24 ,  0.255, ..., -0.085, -0.165, -0.11 ],\n",
              "        ...,\n",
              "        [-0.005,  0.01 ,  0.015, ..., -0.03 ,  0.03 ,  0.02 ],\n",
              "        [-0.004,  0.008,  0.012, ..., -0.024,  0.024,  0.016],\n",
              "        [-0.003,  0.006,  0.009, ..., -0.018,  0.018,  0.012]])]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4DKQUVlQfu9",
        "outputId": "e4fdc1e9-d596-4635-bdf5-16d8834434b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([list(['CD'])], dtype=object)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rzmwwQBOzGM",
        "outputId": "e2d3ec9d-c37b-4183-8a31-edd3a99235d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_out"
      ],
      "metadata": {
        "id": "DjemqWg8FTFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13e30a9-c48c-4a55-e559-36cbacd239d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([list(['CD'])], dtype=object)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqM3hVArRPtg",
        "outputId": "ed46b836-00c4-4eca-9a7b-12ba46759f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9nZz8R9QL8I",
        "outputId": "d01bc0f7-112a-4c6d-cf90-829347dd2dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9853, 5000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('x_patient.pkl', 'wb') as file:\n",
        "    pickle.dump(np.array(x_out), file)\n",
        "\n",
        "with open('y_patient.pkl', 'wb') as file:\n",
        "    pickle.dump(np.array(y_out), file)\n",
        "\n",
        "# with open('new_X_train.pkl', 'wb') as file:\n",
        "#     pickle.dump(np.array(X_train), file)\n",
        "\n",
        "# with open('new_y_train.pkl', 'wb') as file:\n",
        "#     pickle.dump(np.array(y_train), file)"
      ],
      "metadata": {
        "id": "4EJNKH6U3IN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(x_out).shape, np.array(y_out).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f66b2AEHKPBU",
        "outputId": "852924c5-a8ea-4cf2-91cf-8a3eca9b490a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1, 5000, 12), (1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# category mapping to a number\n",
        "num2class = np.array(['NORM', 'MI', 'STTC', 'CD', 'HYP'])\n",
        "\n",
        "def label2num(labels):\n",
        "    for index in range(len(labels)):\n",
        "        labels[index] = np.where(num2class == labels[index][0][0])[0]"
      ],
      "metadata": {
        "id": "slHlqdeidj1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train_copy = y_train.copy()\n",
        "# y_test_copy = y_test.copy()"
      ],
      "metadata": {
        "id": "DgxKnoHKeznm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label2num(y_train_copy)\n",
        "# label2num(y_test_copy)"
      ],
      "metadata": {
        "id": "ktcTjdPShID0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label2num(y_train)\n",
        "label2num(y_test)"
      ],
      "metadata": {
        "id": "XCEUfuvteM9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.flatten().astype(np.int32)\n",
        "y_test = y_test.flatten().astype(np.int32)"
      ],
      "metadata": {
        "id": "1zqnP_l5hBw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "hl8UveHKnUzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43156bdb-4d7c-416b-d2db-a3afdd94a4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9853, 5000, 12), (1901, 5000, 12), (9853,), (1901,))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16"
      ],
      "metadata": {
        "id": "qGjSsnfemWY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "WNGWnlMIo2AM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f02af7f-83f6-47c1-9c64-256ff3304612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9853, 5000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 5000, 12)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 5000, 12)"
      ],
      "metadata": {
        "id": "PzzObVzRm6Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "9Gpc2Fhrp8dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "wtpQ2uPep-Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * out_channels),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out += self.shortcut(x)\n",
        "        out = torch.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "UNtTujAVqIxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "basic_block = BasicBlock(64, 128)\n",
        "print(basic_block)\n",
        "x = torch.randn(2, 64, 500, 12)\n",
        "y = basic_block(x)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98mwp5MSqcH2",
        "outputId": "2407e07f-3591-4534-e380-f58fcc947b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BasicBlock(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (shortcut): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "torch.Size([2, 128, 500, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, zip_channels, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        out_channels = self.expansion * zip_channels\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, zip_channels, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(zip_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(zip_channels, zip_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(zip_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(zip_channels, out_channels, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out += self.shortcut(x)\n",
        "        out = torch.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "4Y-b5Gs-qeoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck = Bottleneck(256, 128)\n",
        "print(bottleneck)\n",
        "x = torch.randn(2, 256, 32, 32)\n",
        "y = bottleneck(x)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-u1l6ZLquso",
        "outputId": "cdb440fc-a9af-4a9e-ad5a-accbcc125f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bottleneck(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (shortcut): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "torch.Size([2, 512, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet architecture for processing input images. This class initializes the network with\n",
        "    convolutional layers, followed by multiple residual blocks, average pooling, and a final\n",
        "    fully connected layer for classification.\n",
        "\n",
        "    The network architecture is designed to process input images and output class scores for\n",
        "    a specified number of classes. It utilizes the concept of residual learning with either\n",
        "    BasicBlock or Bottleneck blocks to enable deep network architectures.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, block, num_blocks, num_classes=5):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=(7, 1), stride=(2, 1), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        # Initialize residual blocks\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "\n",
        "        # Use adaptive average pooling to ensure the output size is (batch_size, channels, 1, 1)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # The classifier linear layer; adjust in_features based on the block expansion and the output of avg_pool\n",
        "        self.classifier = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass input through the initial features\n",
        "        out = self.features(x)\n",
        "\n",
        "        # Pass through each residual layer\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "\n",
        "        # Apply adaptive average pooling and flatten the output\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)  # Flatten the output for the fully connected layer\n",
        "\n",
        "        # Pass through the classifier to get class scores\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "HVZb8Sp7qwmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3,4,6,3])"
      ],
      "metadata": {
        "id": "qn-dnpCoq6Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = ResNet34().to(device)\n",
        "print(net)\n",
        "if device == 'cuda':\n",
        "    net = nn.DataParallel(net)\n",
        "    torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zh3RHBrq77F",
        "outputId": "63f8ba87-d1e2-414a-b3d9-7c9f465d4459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(7, 1), stride=(2, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (4): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (5): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (classifier): Linear(in_features=512, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(2, 1, 500, 12).to(device)\n",
        "y = net(x)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1mffD_5q9xw",
        "outputId": "f1ca3d91-8f6e-4d8b-dba4-ffb50d80ee4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W8NOSkc_rJW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "vb0nn37qrM-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-1\n",
        "momentum = 0.9\n",
        "weight_decay = 5e-4\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, threshold=0.1, patience=3, verbose=True)"
      ],
      "metadata": {
        "id": "PhuJy4wWrOJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training function\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % (epoch))\n",
        "    net.train()\n",
        "    train_loss = torch.Tensor([0.0]).float().to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        if batch_idx % 100 == 99:    # print every 100 mini-batches\n",
        "            print('[%d, %5d] loss: %.6f |  Acc: %.3f%% (%d/%d)' %\n",
        "              (epoch + 1, batch_idx + 1, train_loss.item(), 100.*correct/total, correct, total))\n",
        "    return train_loss"
      ],
      "metadata": {
        "id": "UrkbkXRorOlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = False\n",
        "if load_model:\n",
        "    checkpoint = torch.load('./checkpoint/res18.ckpt')\n",
        "    net.load_state_dict(checkpoint['net'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "else:\n",
        "    start_epoch = 0\n",
        "print('start_epoch: %s' % start_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz1c5T9ZrdUY",
        "outputId": "c3ac58ef-d020-4c32-9a81-14e83a1cc7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_epoch: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(start_epoch, 10):\n",
        "    loss = train(epoch)\n",
        "    print('Total loss: %.6f' % loss)\n",
        "    start_epoch = epoch\n",
        "    scheduler.step(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1P_4nY0rf9X",
        "outputId": "75a4a1fb-ff89-434b-e69d-4465744a87e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "[1,   100] loss: 213.106934 |  Acc: 44.875% (718/1600)\n",
            "[1,   200] loss: 353.771484 |  Acc: 46.156% (1477/3200)\n",
            "[1,   300] loss: 489.882629 |  Acc: 47.021% (2257/4800)\n",
            "[1,   400] loss: 623.595764 |  Acc: 47.797% (3059/6400)\n",
            "[1,   500] loss: 754.764587 |  Acc: 48.600% (3888/8000)\n",
            "[1,   600] loss: 881.958862 |  Acc: 49.531% (4755/9600)\n",
            "Total loss: 902.196594\n",
            "\n",
            "Epoch: 1\n",
            "[2,   100] loss: 118.565224 |  Acc: 56.688% (907/1600)\n",
            "[2,   200] loss: 235.388290 |  Acc: 57.094% (1827/3200)\n",
            "[2,   300] loss: 353.819244 |  Acc: 57.104% (2741/4800)\n",
            "[2,   400] loss: 461.776489 |  Acc: 58.266% (3729/6400)\n",
            "[2,   500] loss: 569.367249 |  Acc: 59.237% (4739/8000)\n",
            "[2,   600] loss: 676.128418 |  Acc: 59.719% (5733/9600)\n",
            "Total loss: 693.427429\n",
            "\n",
            "Epoch: 2\n",
            "[3,   100] loss: 104.237671 |  Acc: 63.500% (1016/1600)\n",
            "[3,   200] loss: 204.618088 |  Acc: 63.312% (2026/3200)\n",
            "[3,   300] loss: 301.828674 |  Acc: 64.000% (3072/4800)\n",
            "[3,   400] loss: 401.999268 |  Acc: 64.062% (4100/6400)\n",
            "[3,   500] loss: 501.656860 |  Acc: 64.287% (5143/8000)\n",
            "[3,   600] loss: 598.154236 |  Acc: 64.583% (6200/9600)\n",
            "Total loss: 614.928772\n",
            "\n",
            "Epoch: 3\n",
            "[4,   100] loss: 94.310387 |  Acc: 65.875% (1054/1600)\n",
            "[4,   200] loss: 187.130249 |  Acc: 66.531% (2129/3200)\n",
            "[4,   300] loss: 278.903961 |  Acc: 67.104% (3221/4800)\n",
            "[4,   400] loss: 369.244781 |  Acc: 67.547% (4323/6400)\n",
            "[4,   500] loss: 462.315186 |  Acc: 67.287% (5383/8000)\n",
            "[4,   600] loss: 556.600281 |  Acc: 67.031% (6435/9600)\n",
            "Total loss: 570.438904\n",
            "\n",
            "Epoch: 4\n",
            "[5,   100] loss: 88.945824 |  Acc: 68.875% (1102/1600)\n",
            "[5,   200] loss: 177.519165 |  Acc: 68.656% (2197/3200)\n",
            "[5,   300] loss: 269.791473 |  Acc: 68.312% (3279/4800)\n",
            "[5,   400] loss: 359.317749 |  Acc: 68.203% (4365/6400)\n",
            "[5,   500] loss: 446.972321 |  Acc: 68.300% (5464/8000)\n",
            "[5,   600] loss: 532.388672 |  Acc: 68.542% (6580/9600)\n",
            "Total loss: 547.019348\n",
            "\n",
            "Epoch: 5\n",
            "[6,   100] loss: 84.017365 |  Acc: 70.562% (1129/1600)\n",
            "[6,   200] loss: 171.067307 |  Acc: 69.781% (2233/3200)\n",
            "[6,   300] loss: 254.056885 |  Acc: 69.812% (3351/4800)\n",
            "[6,   400] loss: 342.080444 |  Acc: 69.547% (4451/6400)\n",
            "[6,   500] loss: 427.474792 |  Acc: 69.650% (5572/8000)\n",
            "[6,   600] loss: 511.091339 |  Acc: 69.990% (6719/9600)\n",
            "Total loss: 525.286621\n",
            "\n",
            "Epoch: 6\n",
            "[7,   100] loss: 90.297813 |  Acc: 68.438% (1095/1600)\n",
            "[7,   200] loss: 176.193649 |  Acc: 69.062% (2210/3200)\n",
            "[7,   300] loss: 259.160156 |  Acc: 69.604% (3341/4800)\n",
            "[7,   400] loss: 343.773071 |  Acc: 69.797% (4467/6400)\n",
            "[7,   500] loss: 428.922760 |  Acc: 69.662% (5573/8000)\n",
            "[7,   600] loss: 515.300781 |  Acc: 69.365% (6659/9600)\n",
            "Total loss: 528.317261\n",
            "\n",
            "Epoch: 7\n",
            "[8,   100] loss: 81.217545 |  Acc: 72.188% (1155/1600)\n",
            "[8,   200] loss: 164.813889 |  Acc: 70.969% (2271/3200)\n",
            "[8,   300] loss: 251.505005 |  Acc: 70.333% (3376/4800)\n",
            "[8,   400] loss: 340.321655 |  Acc: 69.594% (4454/6400)\n",
            "[8,   500] loss: 423.370819 |  Acc: 69.650% (5572/8000)\n",
            "[8,   600] loss: 509.486786 |  Acc: 69.667% (6688/9600)\n",
            "Total loss: 522.532104\n",
            "\n",
            "Epoch: 8\n",
            "[9,   100] loss: 82.916840 |  Acc: 70.312% (1125/1600)\n",
            "[9,   200] loss: 165.736160 |  Acc: 70.406% (2253/3200)\n",
            "[9,   300] loss: 247.842987 |  Acc: 70.625% (3390/4800)\n",
            "[9,   400] loss: 331.654327 |  Acc: 70.516% (4513/6400)\n",
            "[9,   500] loss: 418.028290 |  Acc: 70.375% (5630/8000)\n",
            "[9,   600] loss: 499.581024 |  Acc: 70.406% (6759/9600)\n",
            "Total loss: 513.003235\n",
            "Epoch 00009: reducing learning rate of group 0 to 1.0000e-02.\n",
            "\n",
            "Epoch: 9\n",
            "[10,   100] loss: 76.106316 |  Acc: 72.875% (1166/1600)\n",
            "[10,   200] loss: 150.424042 |  Acc: 72.969% (2335/3200)\n",
            "[10,   300] loss: 224.898712 |  Acc: 73.271% (3517/4800)\n",
            "[10,   400] loss: 300.766571 |  Acc: 73.188% (4684/6400)\n",
            "[10,   500] loss: 371.528473 |  Acc: 73.787% (5903/8000)\n",
            "[10,   600] loss: 441.469330 |  Acc: 74.083% (7112/9600)\n",
            "Total loss: 453.639008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PZfPrq_jNRjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), 'resnet.pth')"
      ],
      "metadata": {
        "id": "yoD_Ui77VjY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "5aNEst1trHbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy('resnet.pth', '/content/gdrive/MyDrive/Physionet_NPY_DATA')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IZx-ObutrQHH",
        "outputId": "0b32aa77-8956-4033-e1d0-9b95574ec842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Physionet_NPY_DATA/resnet.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w_n69xu8rQnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/x_patient.pkl', 'rb') as file:\n",
        "    x_patient = pickle.load(file)"
      ],
      "metadata": {
        "id": "y-dXw8Uarx3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/y_patient.pkl', 'rb') as file:\n",
        "    y_patient = pickle.load(file)"
      ],
      "metadata": {
        "id": "lRkryD7psBdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_patient.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJvOim1OsD85",
        "outputId": "8f4e6944-6940-4bed-ef54-1a6a2acb1fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 5000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming arr is your NumPy array with shape (1, 5000, 12)\n",
        "# arr = ...\n",
        "\n",
        "# Batch size\n",
        "batch_size = 500\n",
        "\n",
        "# Calculate the number of batches\n",
        "num_batches = x_patient.shape[1] // batch_size\n",
        "\n",
        "# Reshape into batches\n",
        "batches = np.array_split(x_patient, num_batches, axis=1)\n",
        "\n",
        "# 'batches' is a list of arrays, each with shape (1, 500, 12)\n",
        "\n",
        "# Accessing individual batches\n",
        "for i, batch in enumerate(batches):\n",
        "    print(f\"Batch {i + 1} shape: {batch.shape}\")\n",
        "    # Do something with the batch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyzJS3atsIVj",
        "outputId": "33f3498d-7df5-42d6-96bf-340974b9d3e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 shape: (1, 500, 12)\n",
            "Batch 2 shape: (1, 500, 12)\n",
            "Batch 3 shape: (1, 500, 12)\n",
            "Batch 4 shape: (1, 500, 12)\n",
            "Batch 5 shape: (1, 500, 12)\n",
            "Batch 6 shape: (1, 500, 12)\n",
            "Batch 7 shape: (1, 500, 12)\n",
            "Batch 8 shape: (1, 500, 12)\n",
            "Batch 9 shape: (1, 500, 12)\n",
            "Batch 10 shape: (1, 500, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.reshape(np.array(batches), (10, 500, 12))"
      ],
      "metadata": {
        "id": "dI1QMUY7u09w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.load(y_train_file_path, allow_pickle=True)\n",
        "y_train = y_train.reshape(len(y_train), 1)\n",
        "\n",
        "y_list = y_train.tolist()\n",
        "\n",
        "temp = None\n",
        "faulty_set = list()\n",
        "count = 0\n",
        "for items in y_train:\n",
        "\n",
        "    if len(items[0]) == 0:\n",
        "       count += 1\n",
        "       temp = items\n",
        "       faulty_set.append(temp)\n",
        "       continue\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tpu_pXk11T0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6frgtVZ2pfR",
        "outputId": "c4004b37-31e7-4e84-ff4b-ba0bdc648ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17302, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = y_train[np.where(y_train != temp)[0]]\n",
        "\n",
        "label2num(y_train)\n",
        "y_train = y_train.flatten().astype(np.int32)"
      ],
      "metadata": {
        "id": "K0DPnlls1qw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvds5I1-CfQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "or65Nv5HE1tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train[24]"
      ],
      "metadata": {
        "id": "a2sLJEEI5Z3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLIu0-wVCQQV",
        "outputId": "ca46e5a7-ca1e-4ea7-d465-667108c10e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "7ixRboQS0eeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.repeat(10, 1)\n",
        "\n",
        "y_train = y_train.squeeze()"
      ],
      "metadata": {
        "id": "o9njzY4KCXez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.unsqueeze(1)\n",
        "\n",
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX7N3MsACIGW",
        "outputId": "4fe06618-748d-4c8d-d13c-733d74defa9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 1, 500, 12]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 1\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "ZDTc8cCRu_Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpRhg4fUzyHA",
        "outputId": "afce421d-b511-426c-d259-fd1a3b78719e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 1, 500, 12]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch = 0\n",
        "for epoch in range(start_epoch, 3):\n",
        "    loss = train(epoch)\n",
        "    print('Total loss: %.6f' % loss)\n",
        "    start_epoch = epoch\n",
        "    scheduler.step(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S6QtdHfzyDq",
        "outputId": "6212fa30-4fc5-418a-934a-5eb83ae3db28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "Total loss: 7.356345\n",
            "\n",
            "Epoch: 1\n",
            "Total loss: 0.297312\n",
            "\n",
            "Epoch: 2\n",
            "Total loss: 0.067956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), 'resnet_finetuned.pth')\n",
        "shutil.copy('resnet_finetuned.pth', '/content/gdrive/MyDrive/Physionet_NPY_DATA')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DmmInY6EGnDS",
        "outputId": "bffa3ebb-72a5-41e7-d15e-889c185d2955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Physionet_NPY_DATA/resnet_finetuned.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi2vuMSPyXgI",
        "outputId": "2087d52b-627e-44ea-8e80-049f72f817c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.,  ..., 0., 3., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d3uoxuOydqj",
        "outputId": "f2098471-dc43-4b26-8ec2-800821100909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 3., 3., 3., 3., 3., 3., 3., 3., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.load(y_train_file_path, allow_pickle=True)\n",
        "y_train = y_train.reshape(len(y_train), 1)\n",
        "\n",
        "y_list = y_train.tolist()\n",
        "\n",
        "temp = None\n",
        "faulty_set = list()\n",
        "count = 0\n",
        "for items in y_train:\n",
        "\n",
        "    if len(items[0]) == 0:\n",
        "       count += 1\n",
        "       temp = items\n",
        "       faulty_set.append(temp)\n",
        "       continue\n",
        "\n",
        "y_train = y_train[np.where(y_train != temp)[0]]\n",
        "\n",
        "label2num(y_train)\n",
        "y_train = y_train.flatten().astype(np.int32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n"
      ],
      "metadata": {
        "id": "G8OCC68YEAPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcsCcMqxEq1h",
        "outputId": "977842c3-5950-4fb5-81d4-88d28c592e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16966])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def add_gaussian_noise(data, noise_level=0.05):\n",
        "    \"\"\"\n",
        "    Adds Gaussian noise to the data.\n",
        "\n",
        "    :param data: Original data array (1, time_points, channels).\n",
        "    :param noise_level: Standard deviation of the Gaussian noise.\n",
        "    :return: Data with added Gaussian noise.\n",
        "    \"\"\"\n",
        "    noise = np.random.normal(0, noise_level, data.shape)\n",
        "    return data + noise\n",
        "\n",
        "def random_time_shift(data, max_shift=100):\n",
        "    \"\"\"\n",
        "    Randomly shifts the data in time.\n",
        "\n",
        "    :param data: Original data array (1, time_points, channels).\n",
        "    :param max_shift: Maximum number of time points to shift.\n",
        "    :return: Time-shifted data.\n",
        "    \"\"\"\n",
        "    shift = np.random.randint(-max_shift, max_shift)\n",
        "    return np.roll(data, shift, axis=1)\n",
        "\n",
        "def scale_amplitude(data, scale_range=(0.8, 1.2)):\n",
        "    \"\"\"\n",
        "    Randomly scales the amplitude of the data.\n",
        "\n",
        "    :param data: Original data array (1, time_points, channels).\n",
        "    :param scale_range: Tuple indicating min and max scaling factors.\n",
        "    :return: Amplitude-scaled data.\n",
        "    \"\"\"\n",
        "    scale_factor = np.random.uniform(scale_range[0], scale_range[1])\n",
        "    return data * scale_factor\n",
        "\n",
        "# Simulate an ECG data sample\n",
        "ecg_data_sample = np.random.rand(1, 500, 12)  # Your ECG data with shape (1, 5000, 12)\n",
        "\n",
        "# Apply augmentations\n",
        "augmented_data = add_gaussian_noise(np.array(batches))\n",
        "augmented_data = random_time_shift(augmented_data)\n",
        "augmented_data = scale_amplitude(augmented_data)\n",
        "\n",
        "print(\"Original Data Shape:\", ecg_data_sample.shape)\n",
        "print(\"Augmented Data Shape:\", augmented_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEbmi2OTErsp",
        "outputId": "f3025457-476e-4d4e-dc4d-fb309a971d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data Shape: (1, 500, 12)\n",
            "Augmented Data Shape: (10, 1, 500, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = ResNet34().to(device)\n",
        "# chk = torch.load('resnet.pth')\n",
        "# model.load_state_dict(chk['model_state_dict'])\n",
        "state_dict = torch.load('/content/resnet.pth')\n",
        "\n",
        "# Apply the weights\n",
        "net.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmsGo7PWH5YO",
        "outputId": "05936f1c-007c-4e8d-9595-48409e7c4f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(augmented_data, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "UaTnLV6XIhi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "NHTaWiqgIJmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlNiI_oyIow-",
        "outputId": "e4d9dcbd-d060-455f-fab5-e41af8ac6542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 1, 500, 12]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "start_epoch = 0\n",
        "for epoch in range(start_epoch, 3):\n",
        "    loss = train(epoch)\n",
        "    print('Total loss: %.6f' % loss)\n",
        "    start_epoch = epoch\n",
        "    scheduler.step(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf01K-TPH7gg",
        "outputId": "ac2252f1-4970-46ff-d1c1-f9afe84f6172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "[1,     1] loss: 1.940569 |  Acc: 0.000% (0/1)\n",
            "[1,     2] loss: 3.569745 |  Acc: 0.000% (0/2)\n",
            "[1,     3] loss: 5.028925 |  Acc: 0.000% (0/3)\n",
            "[1,     4] loss: 6.610187 |  Acc: 0.000% (0/4)\n",
            "[1,     5] loss: 7.994543 |  Acc: 0.000% (0/5)\n",
            "[1,     6] loss: 10.178669 |  Acc: 0.000% (0/6)\n",
            "[1,     7] loss: 11.622543 |  Acc: 0.000% (0/7)\n",
            "[1,     8] loss: 13.881487 |  Acc: 0.000% (0/8)\n",
            "[1,     9] loss: 15.400972 |  Acc: 0.000% (0/9)\n",
            "[1,    10] loss: 17.116020 |  Acc: 0.000% (0/10)\n",
            "Total loss: 17.116020\n",
            "\n",
            "Epoch: 1\n",
            "[2,     1] loss: 1.715048 |  Acc: 0.000% (0/1)\n",
            "[2,     2] loss: 3.296310 |  Acc: 0.000% (0/2)\n",
            "[2,     3] loss: 5.555253 |  Acc: 0.000% (0/3)\n",
            "[2,     4] loss: 7.074739 |  Acc: 0.000% (0/4)\n",
            "[2,     5] loss: 9.258865 |  Acc: 0.000% (0/5)\n",
            "[2,     6] loss: 10.718045 |  Acc: 0.000% (0/6)\n",
            "[2,     7] loss: 12.161920 |  Acc: 0.000% (0/7)\n",
            "[2,     8] loss: 13.546276 |  Acc: 0.000% (0/8)\n",
            "[2,     9] loss: 15.175452 |  Acc: 0.000% (0/9)\n",
            "[2,    10] loss: 17.116020 |  Acc: 0.000% (0/10)\n",
            "Total loss: 17.116020\n",
            "\n",
            "Epoch: 2\n",
            "[3,     1] loss: 1.581262 |  Acc: 0.000% (0/1)\n",
            "[3,     2] loss: 3.040442 |  Acc: 0.000% (0/2)\n",
            "[3,     3] loss: 4.424798 |  Acc: 0.000% (0/3)\n",
            "[3,     4] loss: 5.944283 |  Acc: 0.000% (0/4)\n",
            "[3,     5] loss: 8.128409 |  Acc: 0.000% (0/5)\n",
            "[3,     6] loss: 9.757586 |  Acc: 0.000% (0/6)\n",
            "[3,     7] loss: 11.698154 |  Acc: 0.000% (0/7)\n",
            "[3,     8] loss: 13.957098 |  Acc: 0.000% (0/8)\n",
            "[3,     9] loss: 15.672146 |  Acc: 0.000% (0/9)\n",
            "[3,    10] loss: 17.116020 |  Acc: 0.000% (0/10)\n",
            "Total loss: 17.116020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5m8BuOpII9Na"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}